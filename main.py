from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from dotenv import load_dotenv
import tempfile
import streamlit as st

load_dotenv()

st.set_page_config(
    page_title="Summify",
    page_icon="ðŸ“š"
)

st.header("ðŸ“š Summify")
st.write("Summarize any text or document")
st.markdown("""<hr style="border:1px solid #00BFFF">""", unsafe_allow_html=True)

uploaded_file = st.file_uploader(label = "Upload your PDF", type="pdf", accept_multiple_files=False)
summary_length = st.selectbox(label = "Select summary length", options = [
    "Short(3 or 5 bullet points)", "Medium(1 or 2 paragraphs)", "Detailed(More than 2 paragraphs)"
])
summary_type = st.selectbox(label="Select summary type", options = ["Abstractive", "Extractive"])
summary_tone = st.selectbox(label="Select summary tone", options = ["Academic", "Casual", "Professional"])
summary_model = st.selectbox(label="Select model", options = ["Claude 3.5 Sonnet", "Gemini 1.5 pro", "Mistral-7B-Instruct-v0.2"])

prompt = PromptTemplate(
    template="""Summarize the given document: {uploaded_file} and must consider the following parameters:
    - summary length: {summary_length}
    - summary type: {summary_type}
    - summary tone: {summary_tone}
    """,
    input_variables=["uploaded_file", "summary_length", "summary_type", "summary_tone"]
)

parser = StrOutputParser()

st.divider()

uploaded_data = ""
if st.button("Summarize"):
    if uploaded_file!=None:
        with tempfile.NamedTemporaryFile(delete = False, suffix = ".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_path = tmp_file.name
            loader = PyPDFLoader(temp_path)
            pages = loader.load()
            uploaded_data = " ".join(pages[0].page_content.split())
            st.write(uploaded_data[0:300]+"... ")

    if summary_model == "Claude 3.5 Sonnet":
        model = ChatAnthropic(model = "claude-3-5-sonnet-20241022")
        chain = prompt | model | parser
        response = chain.invoke({"uploaded_file": uploaded_data, "summary_length": summary_length,
                             "summary_type": summary_type, "summary_tone": summary_tone})
        st.write(response)
        st.write("Generated by Claude")
    
    elif summary_model == "Gemini 1.5 pro":
        model = ChatGoogleGenerativeAI(model="gemini-1.5-pro")
        chain = prompt | model | parser
        response = chain.invoke({"uploaded_file": uploaded_data, "summary_length": summary_length,
                             "summary_type": summary_type, "summary_tone": summary_tone})
        st.write(response)
        st.write("Generated by Gemini")

    elif summary_model == "Mistral-7B-Instruct-v0.2":
        llm = HuggingFaceEndpoint(
            repo_id="mistralai/Mistral-7B-Instruct-v0.2",
            task="text generation"
        )
        model = ChatHuggingFace(llm=llm)
        chain = prompt | model | parser
        response = chain.invoke({"uploaded_file": uploaded_data, "summary_length": summary_length,
                             "summary_type": summary_type, "summary_tone": summary_tone})
        st.write(response)
        st.write("Generated by Mistral-7B-Instruct-v0.2")
        